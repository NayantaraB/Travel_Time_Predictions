# -*- coding: utf-8 -*-
"""travel_time_kolkata.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pcNwzOhVMRgbWFoxiY8aEEWodQB_21ht

##  Computing Travel time in Kolkata using Uber Movement data
Inspired by a spatial data science tutorial by [Ujval Gandhi](https://github.com/spatialthoughts)

Uber provides anonymized and aggregated travel time data through [Uber Movement](https://movement.uber.com/) platform for many citites across the world. For India, current and historic data is available for 5 cities - Bangalore, Hyderabad, New Delhi, Mumbai and Kolkata. It also provides the details on the ward boundaries in the form of JSON file.

In this project, we use the open travel time dataset from Uber and leverage open-source routing services for [OpenStreetMap](https://wiki.openstreetmap.org/wiki/About_OpenStreetMap) to compute travel time within Kolkata in India.

**Open datasets**
- Uber Movement - Travel times and ward boundaries
- OpenStreetMap - Get driving distance within city

**Python libraries**
- geopandas
- shapely
- matplotlib
"""

pip install geopandas

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import geopandas as gpd
import numpy as np
import requests
import shapely
import matplotlib.pyplot as plt
import datetime
import os
import math
import random

# %matplotlib inline

"""## Step 1: Reading Datasets

### Travel Times

The Uber Movement Travel Times data comes as a CSV file for each quarter. Here we are using the **Travel Times By Date By Hour Buckets (All Days)** dataset. This data set includes the arithmetic mean, geometric mean, and standard deviations for aggregated travel times between every ward in the city, for every day of the quarter and aggregated into time categories. This is a large dataset with over **7M rows**.

We import the data as a Pandas DataFrame and call `convert_dtypes()` to select the best datatypes for each column.
"""

from google.colab import files
uploaded = files.upload()

travel_times= pd.read_csv('kolkata-wards-2020-1-All-DatesByHourBucketsAggregate.csv')
travel_times = travel_times.convert_dtypes()

travel_times

"""### Ward Boundaries

The travel times dataset contain details of travel between *Zones*. For Indian citites, the zones are **Wards** as defined by the local municipal corporation. This data comes as a **GeoJSON** file that contains the polygon representation of each ward. We use `geopandas` to read the file as a GeoDataFrame.
"""

wards = gpd.read_file('kolkata_wards.json')

wards

fig, ax = plt.subplots(figsize=(10,10))
wards['geometry'].plot(color='grey',ax=ax)

"""## Step 2: Data Preprocessing

**Travel Times**

"""

np.random.seed(0)
travel_times = pd.concat([travel_times]*5, ignore_index=True)

travel_times['random'] = np.random.uniform(0, 1, len(travel_times))

travel_times['travel_time'] = np.exp(travel_times['random']*np.log(travel_times['geometric_standard_deviation_travel_time']) + np.log(travel_times['geometric_mean_travel_time']))

"""The source data contains the travel times grouped by blocks of time (peak/off-peak etc.), defined by start_hour and end_hour columns. To allow us to model this easily, we add a time_period columns and assign an integer category value."""

travel_times

categories_to_hour = {
    1: [0, 6],
    2: [7, 9],
    3: [10, 15],
    4: [16, 18],
    5: [19, 23]
}

def get_time_period(hour):
    for category, (start_hour, end_hour) in categories_to_hour.items():
        if hour >= start_hour and hour <= end_hour:
            return category

travel_times['time_period'] = travel_times['start_hour'].apply(get_time_period)

"""Travel time has a strong correlation with the day of the week. So we compute a new column dow from the day and month columns"""

year = 2020

def get_dow(row):
    return datetime.date(year, int(row['month']), int(row['day'])).weekday()

travel_times['dow'] = travel_times.apply(get_dow, axis=1)

travel_times

"""**Ward Boundaries**

For modeling purposes, we use centroid of each ward to represent the ward. We use GeoPandas centroid() function to get the point geometry representing the centroid.

Our source data comes in the EPSG:4326 WGS84 Geographic Projection - which is not suitable forgeoprocessing operations. To get the accurate centroid computation, we must re-project the data to a Planar Projection. We use a UTM projection suitable for the region of the data - WGS 84 UTM Zone 43N - which is defined by the code EPSG:32643. Once computed, we transform it back to EPSG:4326 and add it to our GeoDataFrame.
"""

centroid_utm = wards.geometry.to_crs('EPSG:32643').centroid
wards['centroid'] = centroid_utm.to_crs('EPSG:4326')

fig, ax = plt.subplots(figsize=(10,10))
wards['geometry'].plot(color='grey',ax=ax)
wards['centroid'].plot(color='red',ax=ax)

"""## Step 3: Distance Computation

We have the travel times for each pair of source and destination wards. The travel time is strongly correlated with the distance between the wards. We need to compute the actual distance along the road network for our ward.
"""

ward_no = wards['MOVEMENT_ID']
index = pd.MultiIndex.from_product([ward_no, ward_no], names = ['sourceid', 'dstid'])

distancematrix = pd.DataFrame(index = index).reset_index()
distancematrix = distancematrix.query('sourceid != dstid')

def get_coordinates(row):
    source_ward = wards[wards['MOVEMENT_ID'] == row['sourceid']].iloc[0]
    dst_ward = wards[wards['MOVEMENT_ID'] == row['dstid']].iloc[0]

    src_lon, src_lat = source_ward['centroid'].x, source_ward['centroid'].y
    dst_lon, dst_lat = dst_ward['centroid'].x, dst_ward['centroid'].y
    return src_lon, src_lat, dst_lon, dst_lat

distancematrix[['src_lon', 'src_lat', 'dst_lon', 'dst_lat']] = distancematrix.apply(get_coordinates, axis=1, result_type='expand')

distancematrix

"""We need to get driving distance between approximately 40,000 coordinates. To do this efficiently, we ran the [Open Source Routing Machine (OSRM)](https://hub.docker.com/r/osrm/osrm-backend/) service locally using docker images provided by the project. OSRM holds the network graph in memory and the routing is extremely fast. We write and apply the following function and get the driving distance in meters."""

def get_distance(row):
    
    coordinates = '{},{};{},{}'.format(
        row['src_lon'], row['src_lat'], row['dst_lon'], row['dst_lat'])
    url = 'http://127.0.0.1:5000/route/v1/driving/'
    response = requests.get(url + coordinates) 
    if response.status_code== 200:
        data = response.json()   
        distance = data['routes'][0]['distance']
    
    return distance